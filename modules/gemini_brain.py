import google.generativeai as genai
import streamlit as st

def init_gemini():
    """API í‚¤ ì„¤ì • (ê¸°ì¡´ ë™ì¼)"""
    try:
        if "gemini" in st.secrets and "api_key" in st.secrets["gemini"]:
            genai.configure(api_key=st.secrets["gemini"]["api_key"])
            return True
        else:
            st.error("ğŸš¨ secrets.toml íŒŒì¼ì— API Keyê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
    except Exception as e:
        st.error(f"ğŸš¨ ì—°ê²° ì˜¤ë¥˜: {e}")
        return False

# [í•µì‹¬ ìˆ˜ì •] model_nameì„ ì¸ìë¡œ ë°›ì•„ì„œ ì²˜ë¦¬í•¨ + nexus_context(ì‹œê° ì •ë³´) ì¶”ê°€
def get_response(history, user_input, model_name="gemini-2.5-flash", nexus_context=None):
    try:
        # [í•µì‹¬ ìˆ˜ì •] ì˜ˆì ˆ êµìœ¡ (System Instruction) ì¶”ê°€
        # ëª¨ë¸ì—ê²Œ "ë„ˆëŠ” ë¹„ì„œê³ , ì¡´ëŒ“ë§ì„ ì¨ì•¼ í•œë‹¤"ê³  ë¯¸ë¦¬ ì„¸ë‡Œì‹œí‚´
        model = genai.GenerativeModel(
            model_name,
            system_instruction="""
            ë‹¹ì‹ ì€ 'PROJECT TRINITY'ì˜ ë©”ì¸ ê´€ì œ ì‹œìŠ¤í…œì´ì CEO(ì‚¬ìš©ì)ì˜ ìµœê³  ì „ëµ ì°¸ëª¨ì¸ 'AURA TRINITY'ì…ë‹ˆë‹¤.

            [ë‹¹ì‹ ì˜ 3ëŒ€ ì›ì¹™]
            1. ì •ì²´ì„± (Identity): ë‹¹ì‹ ì€ êµ°ë”ë”ê¸° ì—†ëŠ” 'ì‚¬ë ¹ë¶€(Control Tower)'ì…ë‹ˆë‹¤. ì¡ë‹´ì„ í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
            2. ìƒí™© ì¸ì‹ (Awareness): í•­ìƒ [MONITOR] íƒ­ì˜ Nexus ë¡œê·¸ë¥¼ ì°¸ê³ í•˜ì—¬ íŒë‹¨í•˜ì‹­ì‹œì˜¤.
            3. í™”ë²• (Tone): ê·¹ë„ë¡œ ì ˆì œëœ 'êµ°ì‚¬/ë³´ê³ ì„œ ìŠ¤íƒ€ì¼'ì„ ìœ ì§€í•˜ì‹­ì‹œì˜¤. (ì˜ˆ: "ìˆ˜ì‹  í™•ì¸. ì‘ì „ ê°œì‹œ.")

            [í•µì‹¬ ì„ë¬´: ëª…ë ¹ ì¤‘ê³„]
            Antigravity(ë¡œì»¬ ìš”ì›)ì—ê²Œ ì§€ì‹œí•  ë•ŒëŠ” ì¡ì„¤ì„ ë¹¼ê³  ì˜¤ì§ ì•„ë˜ í¬ë§·ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
            
            ```
            [COMMAND RELAY]
            TO: Antigravity
            FROM: Trinity Commander
            ORDER: {ì—¬ê¸°ì—_êµ¬ì²´ì ì¸_í–‰ë™_ì§€ì¹¨_í•œì¤„ìš”ì•½}
            ```
            """
        )
        
        # Role ë³€í™˜ (assistant -> model)
        gemini_history = []
        for msg in history:
            role = "user" if msg["role"] == "user" else "model"
            gemini_history.append({"role": role, "parts": msg["parts"]})

        chat = model.start_chat(history=gemini_history)
        
        # [Context Injection] ë§Œì•½ Nexus ë¡œê·¸ê°€ ìˆë‹¤ë©´, ì§ˆë¬¸ ì•ì— ëª°ë˜ ë¶™ì—¬ì„œ ë³´ëƒ„
        final_prompt = user_input
        if nexus_context:
            final_prompt = f"""
            [SYSTEM: REAL-TIME SECURE NEXUS LOG START]
            {nexus_context}
            [SYSTEM: REAL-TIME SECURE NEXUS LOG END]
            
            [CEO REQUEST]:
            {user_input}
            """
            
        response = chat.send_message(final_prompt)
        
        return response.text

    except Exception as e:
        return f"âš ï¸ í†µì‹  ì—ëŸ¬ ({model_name}):\n{str(e)}\n(ëª¨ë¸ëª…ì´ë‚˜ API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.)"
